{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "import pmdarima as pm\n",
    "from pmdarima.arima import auto_arima\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess data\n",
    "\n",
    "aapl = pd.read_csv(\"data_files/AAPL_combined.csv.gz\")\n",
    "nee = pd.read_csv(\"data_files/NEE_combined.csv.gz\")\n",
    "lly = pd.read_csv(\"data_files/LLY_combined.csv.gz\")\n",
    "\n",
    "\n",
    "def data_preprocess(df):\n",
    "    # Rename columns\n",
    "    df.rename(columns={'Unnamed: 0': 'timestamp',\n",
    "                       '1. open': 'open',\n",
    "                       '2. high': 'high',\n",
    "                       '3. low': 'low',\n",
    "                       '4. close': 'close',\n",
    "                       '5. volume': 'volume'}, inplace=True)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    if 'Unnamed: 0.1' in df.columns.tolist():\n",
    "        df.drop(columns=['Unnamed: 0.1'], inplace=True)\n",
    "\n",
    "    # Handle data types\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    return df\n",
    "\n",
    "aapl = data_preprocess(aapl)\n",
    "nee = data_preprocess(nee)\n",
    "lly = data_preprocess(lly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily volatility\n",
    "\n",
    "def daily_volatility(df):\n",
    "    \"\"\"\n",
    "    Aggregates to daily level and calculates volatility based on the \n",
    "    logic: sqrt(log(1 + (close - open) / open))\n",
    "    \"\"\"\n",
    "    # Select columns and drop NAs\n",
    "    df = df[['timestamp', 'open', 'close']].dropna().copy()\n",
    "    \n",
    "    # Convert timestamp to datetime and extract the date\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    \n",
    "    # Group by date to get first open and last close\n",
    "    daily = df.groupby('date').agg(\n",
    "        open=('open', 'first'),\n",
    "        close=('close', 'last')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate log return\n",
    "    # equivalent to R: log(1 + (close - open) / open) -> log(close / open)\n",
    "    daily['log_return'] = np.log(1 + (daily['close'] - daily['open']) / daily['open'])\n",
    "    \n",
    "    # Calculate volatility\n",
    "    # Note: If log_return is negative, sqrt will result in NaN. \n",
    "    # We use np.sqrt where valid, otherwise NaN.\n",
    "    daily['volatility'] = daily['log_return'].apply(lambda x: np.sqrt(x) if x > 0 else np.nan)\n",
    "    \n",
    "    # Return only date and volatility, dropping any rows where calculation failed (NaNs)\n",
    "    return daily[['date', 'volatility']].dropna()\n",
    "\n",
    "aapl_vol = daily_volatility(aapl)\n",
    "nee_vol = daily_volatility(nee)\n",
    "lly_vol = daily_volatility(lly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily returns\n",
    "\n",
    "def get_daily_returns(df):\n",
    "\n",
    "    df = df[['timestamp', 'open', 'close']].dropna().copy()\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    \n",
    "    # Aggregation\n",
    "    daily = df.groupby('date').agg(\n",
    "        open=('open', 'first'),\n",
    "        close=('close', 'last')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate Log Return\n",
    "    daily['log_return'] = np.log(daily['close'] / daily['open'])\n",
    "    daily['scaled_return'] = daily['log_return'] * 100\n",
    "    \n",
    "    return daily[['date', 'scaled_return']].dropna()\n",
    "\n",
    "aapl_returns = get_daily_returns(aapl)\n",
    "nee_returns = get_daily_returns(nee)\n",
    "lly_returns = get_daily_returns(lly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build  Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_arima(df):\n",
    "\n",
    "    series = df['volatility'].values\n",
    "\n",
    "    model = auto_arima(series, seasonal=False, error_action='ignore', suppress_warnings=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_arima = fit_arima(aapl_vol)\n",
    "nee_arima = fit_arima(nee_vol)\n",
    "lly_arima = fit_arima(lly_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_garch_pq(df, p, q):    \n",
    "    # Model\n",
    "    model = arch_model(df['scaled_return'], vol='Garch', p=p, q=q, mean='Zero')\n",
    "    results = model.fit(disp='off')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       Zero Mean - GARCH Model Results                        \n",
       "==============================================================================\n",
       "Dep. Variable:          scaled_return   R-squared:                       0.000\n",
       "Mean Model:                 Zero Mean   Adj. R-squared:                  0.001\n",
       "Vol Model:                      GARCH   Log-Likelihood:               -2749.35\n",
       "Distribution:                  Normal   AIC:                           5504.70\n",
       "Method:            Maximum Likelihood   BIC:                           5520.53\n",
       "                                        No. Observations:                 1444\n",
       "Date:                Mon, Dec 08 2025   Df Residuals:                     1444\n",
       "Time:                        11:47:20   Df Model:                            0\n",
       "                             Volatility Model                             \n",
       "==========================================================================\n",
       "                 coef    std err          t      P>|t|    95.0% Conf. Int.\n",
       "--------------------------------------------------------------------------\n",
       "omega          0.5354      0.235      2.279  2.267e-02 [7.495e-02,  0.996]\n",
       "alpha[1]       0.0694  2.913e-02      2.382  1.724e-02 [1.228e-02,  0.126]\n",
       "beta[1]        0.7335      0.101      7.244  4.369e-13   [  0.535,  0.932]\n",
       "==========================================================================\n",
       "\n",
       "Covariance estimator: robust\n",
       "ARCHModelResult, id: 0x167a92230"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_garch = fit_garch_pq(aapl_returns, 3, 2)\n",
    "nee_garch = fit_garch_pq(nee_returns, 2, 2)\n",
    "lly_garch = fit_garch_pq(lly_returns, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse217a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
